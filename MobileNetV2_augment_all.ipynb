{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8813a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "from google.cloud import storage\n",
    "import tensorflow_hub as hub\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99bafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_augment2x_siebren.csv\", header=None)\n",
    "val_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_augment_siebren.csv\", header=None)\n",
    "test_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_augment_siebren.csv\", header=None)\n",
    "CLASS_NAMES = train_data[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d5e6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# 10 is a magic number tuned for local training of this dataset.\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "VALIDATION_IMAGES = 370\n",
    "VALIDATION_STEPS = VALIDATION_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b75a4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img, reshape_dims):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # Resize the image to the desired size.\n",
    "    return tf.image.resize(img, reshape_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a00a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "img_list = []\n",
    "\n",
    "def read_and_preprocess(image_bytes, label, augment):\n",
    "    if augment == \"True\":\n",
    "        img = decode_img(image_bytes, [IMG_WIDTH, IMG_HEIGHT])\n",
    "        img = tf.image.flip_left_right(img)\n",
    "#         img = decode_img(image_bytes, [IMG_HEIGHT + 10, IMG_WIDTH + 10])\n",
    "#         img = tf.image.random_crop(img, [IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "#         img = tf.image.random_flip_left_right(img)\n",
    "#         img = tf.image.random_brightness(img, MAX_DELTA)\n",
    "#         img = tf.image.random_contrast(img, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "    else:\n",
    "        img = decode_img(image_bytes, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f270c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_csv(csv_row):\n",
    "    record_defaults = [\"img\", \"path\", \"augment\"]\n",
    "    \n",
    "    label_string, filename, augment = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    label = tf.math.equal(CLASS_NAMES, label_string)\n",
    "\n",
    "    return image_bytes, label, augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a1dae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(csv_of_filenames, batch_size, training=True):    \n",
    "    dataset = tf.data.TextLineDataset(filenames=csv_of_filenames) \\\n",
    "        .map(decode_csv, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset \\\n",
    "        .map(read_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "        .repeat(count=1)  # Each photo used once.\n",
    "    \n",
    "    # Prefetch prepares the next set of batches while current batch is in use.\n",
    "    return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "#     return dataset.range(4).interleave(lambda _: dataset.batch(batch_size=batch_size), num_parallel_calls=tf.data.AUTOTUNE )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ba417",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5663ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_augment2x_siebren.csv\"\n",
    "eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_augment_siebren.csv\"\n",
    "nclasses = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90793b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.MobileNetV2(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68fe1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c51b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(nclasses, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dbc193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/MobileNetV2_augmented2x/saved_weights/cp.ckpt\")\n",
    "# model = keras.models.load_model(\"gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/Xception_augmented2x_finetuned/model.H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb0250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13eec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28)                35868     \n",
      "=================================================================\n",
      "Total params: 2,293,852\n",
      "Trainable params: 35,868\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1395a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "train_ds = load_dataset(train_path, BATCH_SIZE)\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eec43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/MobileNetV2_augmented2x/saved_weights/cp.ckpt\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a87d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3807/3807 [==============================] - 3455s 906ms/step - loss: 1.3308 - accuracy: 0.5894 - val_loss: 0.9184 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00001: saving model to gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/MobileNetV2_augmented2x/saved_weights/cp.ckpt\n",
      "Epoch 2/5\n",
      "1696/3807 [============>.................] - ETA: 27:24 - loss: 1.0726 - accuracy: 0.6537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3807/3807 [==============================] - 2524s 663ms/step - loss: 1.0610 - accuracy: 0.6572 - val_loss: 0.8963 - val_accuracy: 0.7035\n",
      "\n",
      "Epoch 00003: saving model to gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/MobileNetV2_augmented2x/saved_weights/cp.ckpt\n",
      "Epoch 4/5\n",
      " 827/3807 [=====>........................] - ETA: 37:06 - loss: 1.0640 - accuracy: 0.6555"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "            epochs=5,\n",
    "#             steps_per_epoch=(len(train_data) // BATCH_SIZE),\n",
    "            validation_data=eval_ds,\n",
    "            callbacks=[cp_callback]\n",
    "#             validation_steps=(len(val_data) // BATCH_SIZE)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc46ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb3f01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "train_ds = load_dataset(train_path, BATCH_SIZE)\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e5a719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7614/7614 [==============================] - 6073s 797ms/step - loss: 0.9195 - accuracy: 0.7141 - val_loss: 0.5188 - val_accuracy: 0.8364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "            epochs=1,\n",
    "#             steps_per_epoch=(len(train_data) // BATCH_SIZE),\n",
    "            validation_data=eval_ds,\n",
    "#             validation_steps=(len(val_data) // BATCH_SIZE)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4410a1",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/Xception_augmented2x_finetuned2/model.H5\", \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a2fe7",
   "metadata": {},
   "source": [
    "# Myanmar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29644a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_myan = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_myanmar_augment_siebren.csv\", header=None)\n",
    "test_path_myan = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_myanmar_augment_siebren.csv\"\n",
    "test_ds_myan = load_dataset(test_path_myan, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba49cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,32,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/mobilenetv2_1.00_224/Conv1/Conv2D (defined at <ipython-input-13-e5372f37fa0e>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_36709]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-929f51be8b56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0meval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,32,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/mobilenetv2_1.00_224/Conv1/Conv2D (defined at <ipython-input-13-e5372f37fa0e>:1) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_36709]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)\n",
    "test_loss, test_acc = model.evaluate(eval_ds, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c0df23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "serengeti = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/serengeti_siebren_augment.csv\", header=None)\n",
    "serengeti_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/serengeti_siebren_augment.csv\"\n",
    "test_ds_serengeti = load_dataset(serengeti_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b171cf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 382s 4s/step - loss: 0.6062 - accuracy: 0.5475\n",
      "0.44828563928604126\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds_serengeti, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e68625",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = len(test_data_myan)//BATCH_SIZE\n",
    "y_test = []\n",
    "counter = 0\n",
    "for i in tqdm(test_ds_myan):\n",
    "    if counter < PREDICTIONS:\n",
    "        counter += 1\n",
    "        for j in i[1]:\n",
    "            y_test.append(np.where(j == True)[0][0])\n",
    "    else:\n",
    "        break\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25daacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(test_ds_myan, steps=PREDICTIONS)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "true_categories = y_test\n",
    "y, idx = tf.unique(predicted_categories)\n",
    "cm = confusion_matrix(predicted_categories, true_categories, normalize=\"pred\", labels=y.numpy())\n",
    "cmn = cm\n",
    "df_cm = pd.DataFrame(cmn, index = [CLASS_NAMES[i] for i in y.numpy()],\n",
    "                  columns = [CLASS_NAMES[i] for i in y.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,14))\n",
    "sn.heatmap(df_cm, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c804fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_classified = {}\n",
    "total = {}\n",
    "for idx, i in enumerate(true_categories):\n",
    "    if i == predicted_categories[idx].numpy():\n",
    "        if CLASS_NAMES[i] in correctly_classified.keys():\n",
    "            correctly_classified[CLASS_NAMES[i]] += 1\n",
    "        else:\n",
    "            correctly_classified[CLASS_NAMES[i]] = 1\n",
    "    \n",
    "    if CLASS_NAMES[i] in total.keys():\n",
    "        total[CLASS_NAMES[i]] += 1\n",
    "    else:\n",
    "        total[CLASS_NAMES[i]] = 1\n",
    "            \n",
    "print(\"correct:\", correctly_classified)\n",
    "print(\"total:  \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d78be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "index = 0\n",
    "for idx, i in enumerate(test_ds_myan):   \n",
    "    for j in i[0]:\n",
    "#         if y_pred[index][y_pred[index].argmax()] > 0.90:\n",
    "        if predicted_categories[index].numpy() != true_categories[index]:\n",
    "            plt.figure(figsize = (16,16))\n",
    "            plt.imshow(j)\n",
    "            plt.show()\n",
    "            print(\"Prediction: \"+ str(CLASS_NAMES[predicted_categories[index].numpy()]))\n",
    "            print(\"True: \"+ str(CLASS_NAMES[true_categories[index]]))\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8afac",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a47ff789",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_augment_siebren.csv\"\n",
    "test_ds = load_dataset(test_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08ed3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/682 [==============================] - 140s 204ms/step - loss: 1.3775 - accuracy: 0.6342\n",
      "0.6342291235923767\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d0ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a135221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdcbe6f59d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label = 'train_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 10])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3539b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:13,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PREDICTIONS = len(test_data)//BATCH_SIZE\n",
    "y_test = []\n",
    "counter = 0\n",
    "for i in tqdm(test_ds):\n",
    "    if counter < PREDICTIONS:\n",
    "        counter += 1\n",
    "        for j in i[1]:\n",
    "            y_test.append(np.where(j == True)[0][0])\n",
    "    else:\n",
    "        break\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bceefdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds, steps=PREDICTIONS)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "true_categories = y_test\n",
    "cmn = confusion_matrix(predicted_categories, true_categories, normalize=\"true\")\n",
    "\n",
    "df_cm = pd.DataFrame(cmn, index = [i for i in CLASS_NAMES],\n",
    "                  columns = [i for i in CLASS_NAMES])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
