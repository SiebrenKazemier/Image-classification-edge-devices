{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7d9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "from google.cloud import storage\n",
    "import tensorflow_hub as hub\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f493841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_grouped_classes.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_4classes.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_augment2x_siebren.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_augment_siebren.csv\", header=None)\n",
    "train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_grouped_classes_balanced.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_4classes_balanced.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_elephant.csv\", header=None)\n",
    "\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_series_250_shuffle.csv\", header=None)\n",
    "# train_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_series_200_shuffle_4classes.csv\", header=None)\n",
    "\n",
    "val_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren.csv\", header=None)\n",
    "test_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren.csv\", header=None)\n",
    "CLASS_NAMES = train_data[0].unique()\n",
    "\n",
    "train_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren.csv\"\n",
    "eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e505bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43612"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5429b555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bird</th>\n",
       "      <td>4742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blank</th>\n",
       "      <td>23956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buffalo_African</th>\n",
       "      <td>4826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat_Golden</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chevrotain_Water</th>\n",
       "      <td>3461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chimpanzee</th>\n",
       "      <td>4133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Civet_African_Palm</th>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duiker_Blue</th>\n",
       "      <td>23997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duiker_Red</th>\n",
       "      <td>23945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duiker_Yellow_Backed</th>\n",
       "      <td>11537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elephant_African</th>\n",
       "      <td>24054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genet</th>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gorilla</th>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guineafowl_Black</th>\n",
       "      <td>9403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guineafowl_Crested</th>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hog_Red_River</th>\n",
       "      <td>18020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <td>24104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leopard_African</th>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mandrillus</th>\n",
       "      <td>5306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mongoose</th>\n",
       "      <td>4165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mongoose_Black_Footed</th>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monkey</th>\n",
       "      <td>3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pangolin</th>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Porcupine_Brush_Tailed</th>\n",
       "      <td>10214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rail_Nkulengu</th>\n",
       "      <td>2562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rat_Giant</th>\n",
       "      <td>25013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodent</th>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Squirrel</th>\n",
       "      <td>8531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            1\n",
       "0                            \n",
       "Bird                     4742\n",
       "Blank                   23956\n",
       "Buffalo_African          4826\n",
       "Cat_Golden                276\n",
       "Chevrotain_Water         3461\n",
       "Chimpanzee               4133\n",
       "Civet_African_Palm        716\n",
       "Duiker_Blue             23997\n",
       "Duiker_Red              23945\n",
       "Duiker_Yellow_Backed    11537\n",
       "Elephant_African        24054\n",
       "Genet                    2353\n",
       "Gorilla                   461\n",
       "Guineafowl_Black         9403\n",
       "Guineafowl_Crested       1159\n",
       "Hog_Red_River           18020\n",
       "Human                   24104\n",
       "Leopard_African          1216\n",
       "Mandrillus               5306\n",
       "Mongoose                 4165\n",
       "Mongoose_Black_Footed    1052\n",
       "Monkey                   3025\n",
       "Pangolin                  586\n",
       "Porcupine_Brush_Tailed  10214\n",
       "Rail_Nkulengu            2562\n",
       "Rat_Giant               25013\n",
       "Rodent                    815\n",
       "Squirrel                 8531"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b390f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "# 10 is a magic number tuned for local training of this dataset.\n",
    "SHUFFLE_BUFFER = 10 * BATCH_SIZE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "VALIDATION_IMAGES = 370\n",
    "VALIDATION_STEPS = VALIDATION_IMAGES // BATCH_SIZE\n",
    "\n",
    "def load_dataset(csv_of_filenames, batch_size, training=True):    \n",
    "    dataset = tf.data.TextLineDataset(filenames=csv_of_filenames) \\\n",
    "        .map(decode_csv, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if training:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess_with_augment, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "            .repeat(count=1)\n",
    "    else:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "            .repeat(count=1)  # Each photo used once.\n",
    "    \n",
    "    return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "    record_defaults = [\"img\", \"path\"]\n",
    "    label_string, filename = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    label = tf.math.equal(CLASS_NAMES, label_string)\n",
    "    return image_bytes, label\n",
    "\n",
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "def read_and_preprocess(image_bytes, label, random_augment=False):\n",
    "    img = decode_img(image_bytes, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def read_and_preprocess_with_augment(image_bytes, label):\n",
    "    return read_and_preprocess(image_bytes, label, random_augment=True)\n",
    "\n",
    "def decode_img(img, reshape_dims):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # Resize the image to the desired size.\n",
    "    return tf.image.resize(img, reshape_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abc82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"gs://dataset-gabon/train_val_test_csv_Siebren/CNN_models/Xception/model.H5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ad7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "train_ds = load_dataset(train_path, BATCH_SIZE)\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77354d2",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c87d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476/476 [==============================] - 12294s 26s/step - loss: 0.7292 - accuracy: 0.7636\n",
      "0.7629993557929993\n"
     ]
    }
   ],
   "source": [
    "eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren.csv\"\n",
    "# eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren_grouped_classes.csv\"\n",
    "# eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren_4classes.csv\"\n",
    "# eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren_grouped_classes_balanced2.csv\"\n",
    "# eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_4classes_siebren.csv\"\n",
    "# eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren_series_200_shuffle_4classes.csv\"\n",
    "# eval_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/val_data_siebren_4classes_balanced.csv\"\n",
    "\n",
    "\n",
    "eval_ds = load_dataset(eval_path, BATCH_SIZE, training=False)\n",
    "test_loss, test_acc = model.evaluate(eval_ds, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c94dca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/train_data_siebren_4classes.csv\"\n",
    "# test_ds = load_dataset(test_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f630fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren.csv\"\n",
    "# # test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren_grouped_classes.csv\"\n",
    "# test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren_4classes.csv\"\n",
    "# # test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren_grouped_classes_balanced2.csv\"\n",
    "# test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_4classes_siebren.csv\"\n",
    "# test_path = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren_4classes_balanced.csv\"\n",
    "\n",
    "test_ds = load_dataset(test_path, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4996d8a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8b1155e29984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bcaba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [01:05,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PREDICTIONS = len(test_data)//BATCH_SIZE\n",
    "y_test = []\n",
    "counter = 0\n",
    "for i in tqdm(test_ds):\n",
    "    if counter < PREDICTIONS:\n",
    "        counter += 1\n",
    "        for j in i[1]:\n",
    "            y_test.append(np.where(j == True)[0][0])\n",
    "    else:\n",
    "        break\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae7b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds, steps=PREDICTIONS)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "true_categories = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52e1f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2868.0</td>\n",
       "      <td>Rat_Giant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>764.0</td>\n",
       "      <td>Squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4976.0</td>\n",
       "      <td>Duiker_Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>338.0</td>\n",
       "      <td>Rodent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4994.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>310.0</td>\n",
       "      <td>Guineafowl_Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>Duiker_Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>Duiker_Yellow_Backed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4978.0</td>\n",
       "      <td>Elephant_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rail_Nkulengu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>689.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>Mandrillus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>396.0</td>\n",
       "      <td>Chevrotain_Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>904.0</td>\n",
       "      <td>Porcupine_Brush_Tailed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.62</td>\n",
       "      <td>646.0</td>\n",
       "      <td>Leopard_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>323.0</td>\n",
       "      <td>Mongoose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>3533.0</td>\n",
       "      <td>Hog_Red_River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>Chimpanzee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Guineafowl_Crested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>483.0</td>\n",
       "      <td>Buffalo_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>323.0</td>\n",
       "      <td>Genet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Mongoose_Black_Footed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Civet_African_Palm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>132.0</td>\n",
       "      <td>Pangolin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>718.0</td>\n",
       "      <td>Gorilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.23</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Cat_Golden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.62</td>\n",
       "      <td>43520.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>43520.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>43520.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall  f1-score  support                   label\n",
       "0                 0.75   0.51      0.60   2868.0               Rat_Giant\n",
       "1                 0.15   0.18      0.16    764.0                Squirrel\n",
       "2                  0.6   0.79      0.68   4976.0              Duiker_Red\n",
       "3                 0.11   0.07      0.09    338.0                  Rodent\n",
       "4                  0.8   0.93      0.86   4994.0                   Human\n",
       "5                 0.48   0.77      0.59    310.0        Guineafowl_Black\n",
       "6                 0.18   0.19      0.18   1009.0                  Monkey\n",
       "7                 0.55   0.53      0.54   4998.0             Duiker_Blue\n",
       "8                  0.6   0.48      0.53   1089.0    Duiker_Yellow_Backed\n",
       "9                  0.7   0.89      0.78   4978.0        Elephant_African\n",
       "10                 0.0    0.0      0.00      6.0           Rail_Nkulengu\n",
       "11                0.17   0.25      0.20    689.0                    Bird\n",
       "12                0.75   0.82      0.78   5000.0                   Blank\n",
       "13                0.88   0.27      0.41   2623.0              Mandrillus\n",
       "14                0.15   0.17      0.16    396.0        Chevrotain_Water\n",
       "15                0.37   0.31      0.34    904.0  Porcupine_Brush_Tailed\n",
       "16                0.87   0.49      0.62    646.0         Leopard_African\n",
       "17                0.34   0.27      0.30    323.0                Mongoose\n",
       "18                0.54   0.38      0.45   3533.0           Hog_Red_River\n",
       "19                 0.6   0.67      0.63   1057.0              Chimpanzee\n",
       "20                0.45   0.15      0.23     66.0      Guineafowl_Crested\n",
       "21                0.41   0.34      0.37    483.0         Buffalo_African\n",
       "22                 0.4   0.71      0.51    323.0                   Genet\n",
       "23                0.34    0.2      0.25    163.0   Mongoose_Black_Footed\n",
       "24                0.12   0.16      0.14     61.0      Civet_African_Palm\n",
       "25                0.12   0.01      0.01    132.0                Pangolin\n",
       "26                0.78   0.52      0.62    718.0                 Gorilla\n",
       "27                0.71   0.14      0.23     73.0              Cat_Golden\n",
       "accuracy             -      -      0.62  43520.0                       -\n",
       "macro avg         0.46    0.4      0.40  43520.0                       -\n",
       "weighted avg      0.63   0.62      0.60  43520.0                       -"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = CLASS_NAMES.copy()\n",
    "report = classification_report(true_categories, predicted_categories, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "if new_labels[len(new_labels) -1] != \"-\":\n",
    "    new_labels = np.append(new_labels, [\"-\", \"-\", \"-\"])\n",
    "df = df.round(decimals=2)\n",
    "df['label'] = new_labels\n",
    "df[\"precision\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"recall\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"support\"].iloc[len(new_labels) -3] = df[\"support\"].iloc[len(new_labels) -2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c437e323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f0.5 score:  0.83\n",
      "Human f0.5 score:  0.85\n",
      "Other f0.5 score:  0.93\n",
      "Elephant f0.5 score:  0.74\n"
     ]
    }
   ],
   "source": [
    "macro_f1_score = []\n",
    "sum_list_recall = []\n",
    "sum_list_precision = []\n",
    "for idx, item in df.iterrows():\n",
    "    if idx != \"accuracy\" and idx != \"macro avg\" and idx != \"weighted avg\":\n",
    "        if item[\"label\"] == \"Human\" or item[\"label\"] == \"Elephant_African\" or item[\"label\"] == \"Blank\":\n",
    "            if item[\"precision\"] != 0 and item[\"recall\"] != 0:\n",
    "                macro_f1_score.append(1.5 * (item[\"precision\"] * item[\"recall\"]) / ((0.5*item[\"precision\"]) + item[\"recall\"]))\n",
    "            else:\n",
    "                macro_f1_score.append(0)\n",
    "        else:\n",
    "            sum_list_recall.append(item[\"recall\"])\n",
    "            sum_list_precision.append(item[\"precision\"])\n",
    "\n",
    "recall = sum(sum_list_recall) / len(sum_list_recall)\n",
    "precision = sum(sum_list_precision) / len(sum_list_precision)\n",
    "            \n",
    "macro_f1_score.append(1.5 * (precision * recall) / ((0.5*precision) + recall))\n",
    "\n",
    "print(\"Macro f0.5 score: \", round(sum(macro_f1_score) / len(macro_f1_score), 2))\n",
    "print(\"Human f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Human\"][\"recall\"][0] * df[df[\"label\"] == \"Human\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Human\"][\"precision\"][0]) + df[df[\"label\"] == \"Human\"][\"recall\"][0]), 2))\n",
    "print(\"Other f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Other_animal\"][\"recall\"][0] * df[df[\"label\"] == \"Other_animal\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Other_animal\"][\"precision\"][0]) + df[df[\"label\"] == \"Other_animal\"][\"recall\"][0]), 2))\n",
    "try:\n",
    "    print(\"Elephant f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Elephant_African\"][\"recall\"][0] * df[df[\"label\"] == \"Elephant_African\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Elephant_African\"][\"precision\"][0]) + df[df[\"label\"] == \"Elephant_African\"][\"recall\"][0]), 2))\n",
    "except:\n",
    "    print(\"Elephant f0.5 score: \", 0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57b07a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aggregated_cross_entropy_loss = {}\n",
    "\n",
    "for idx, pred in enumerate(y_pred):\n",
    "    loss = -math.log(pred[true_categories[idx]])\n",
    "    if CLASS_NAMES[true_categories[idx]] in mean_aggregated_cross_entropy_loss:\n",
    "        mean_aggregated_cross_entropy_loss[CLASS_NAMES[true_categories[idx]]].append(loss)\n",
    "    else:\n",
    "        mean_aggregated_cross_entropy_loss[CLASS_NAMES[true_categories[idx]]] = [loss]\n",
    "\n",
    "for keys, values in mean_aggregated_cross_entropy_loss.items():\n",
    "    mean = sum(values)/ len(values)\n",
    "    mean_aggregated_cross_entropy_loss[keys] = round(mean, 2)\n",
    "    \n",
    "# mean_aggregated_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19787d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean aggregated cross entropy loss:  0.64\n",
      "coss entropy loss Human:  0.48\n",
      "coss entropy loss Elephant:  0.75\n",
      "coss entropy loss Other:  0.21\n",
      "coss entropy loss blank:  1.1\n"
     ]
    }
   ],
   "source": [
    "mean_aggregated_cross_entropy_loss_final = []\n",
    "sum_values = []\n",
    "for key, value in mean_aggregated_cross_entropy_loss.items():\n",
    "    if key == \"Human\" or key == \"Elephant_African\" or key == \"Blank\":\n",
    "        mean_aggregated_cross_entropy_loss_final.append(value)\n",
    "    else:\n",
    "        sum_values.append(value)\n",
    "\n",
    "mean_aggregated_cross_entropy_loss_final.append(sum(sum_values) / len(sum_values))\n",
    "\n",
    "print(\"mean aggregated cross entropy loss: \", round(sum(mean_aggregated_cross_entropy_loss_final) / len(mean_aggregated_cross_entropy_loss_final), 2))\n",
    "print(\"coss entropy loss Human: \", mean_aggregated_cross_entropy_loss[\"Human\"])\n",
    "print(\"coss entropy loss Elephant: \", mean_aggregated_cross_entropy_loss[\"Elephant_African\"])\n",
    "print(\"coss entropy loss Other: \", mean_aggregated_cross_entropy_loss[\"Other_animal\"])\n",
    "print(\"coss entropy loss blank: \", mean_aggregated_cross_entropy_loss[\"Blank\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80aa657",
   "metadata": {},
   "source": [
    "# MYANMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842b867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_myan = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_myanmar_siebren.csv\", header=None)\n",
    "test_path_myan = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_myanmar_siebren.csv\"\n",
    "test_ds_myan = load_dataset(test_path_myan, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a0e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     17/Unknown - 515s 30s/step - loss: 0.6855 - accuracy: 0.7693"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cbf89443ae31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds_myan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds_myan, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3da2043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [05:48,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PREDICTIONS = len(test_data_myan)//BATCH_SIZE\n",
    "y_test = []\n",
    "counter = 0\n",
    "for i in tqdm(test_ds_myan):\n",
    "    if counter < PREDICTIONS:\n",
    "        counter += 1\n",
    "        for j in i[1]:\n",
    "            y_test.append(np.where(j == True)[0][0])\n",
    "    else:\n",
    "        break\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e740fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds_myan, steps=PREDICTIONS)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "true_categories = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e242d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hog_Red_River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Buffalo_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Duiker_Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.20</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Elephant_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chimpanzee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Duiker_Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Leopard_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.17</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall  f1-score  support             label\n",
       "0                 0.96   0.74      0.84   2047.0             Human\n",
       "1                  0.0    0.0      0.00      0.0     Hog_Red_River\n",
       "2                 0.87   0.87      0.87   2495.0             Blank\n",
       "3                  0.0    0.0      0.00      0.0   Buffalo_African\n",
       "4                  0.0    0.0      0.00      0.0       Duiker_Blue\n",
       "5                 0.12   0.71      0.20     66.0  Elephant_African\n",
       "9                  0.0    0.0      0.00      0.0        Chimpanzee\n",
       "13                 0.0    0.0      0.00      0.0        Duiker_Red\n",
       "14                 0.0    0.0      0.00      0.0              Bird\n",
       "16                 0.0    0.0      0.00      0.0   Leopard_African\n",
       "22                 0.0    0.0      0.00      0.0            Monkey\n",
       "accuracy             -      -      0.81   4608.0                 -\n",
       "macro avg         0.18   0.21      0.17   4608.0                 -\n",
       "weighted avg       0.9   0.81      0.85   4608.0                 -"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = CLASS_NAMES.copy()\n",
    "report = classification_report(true_categories, predicted_categories, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "a = pd.Series(list(new_labels))\n",
    "b = list(df.index[:-3])\n",
    "b = list(map(int, b))\n",
    "new_labels = list(a[b])\n",
    "if new_labels[len(new_labels) -1] != \"-\":\n",
    "    new_labels = np.append(new_labels, [\"-\", \"-\", \"-\"])\n",
    "df = df.round(decimals=2)\n",
    "df['label'] = new_labels\n",
    "df[\"precision\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"recall\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"support\"].iloc[len(new_labels) -3] = df[\"support\"].iloc[len(new_labels) -2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb0720be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f0.5 score:  0.64\n",
      "Human f0.5 score:  0.87\n",
      "Elephant f0.5 score:  0.17\n"
     ]
    }
   ],
   "source": [
    "macro_f1_score = []\n",
    "sum_list_recall = []\n",
    "sum_list_precision = []\n",
    "for idx, item in df.iterrows():\n",
    "    if idx != \"accuracy\" and idx != \"macro avg\" and idx != \"weighted avg\":\n",
    "        if item[\"label\"] == \"Human\" or item[\"label\"] == \"Elephant_African\" or item[\"label\"] == \"Blank\":\n",
    "            if item[\"precision\"] != 0 and item[\"recall\"] != 0:\n",
    "                macro_f1_score.append(1.5 * (item[\"precision\"] * item[\"recall\"]) / ((0.5*item[\"precision\"]) + item[\"recall\"]))\n",
    "            else:\n",
    "                macro_f1_score.append(0)\n",
    "\n",
    "print(\"Macro f0.5 score: \", round(sum(macro_f1_score) / len(macro_f1_score), 2))\n",
    "print(\"Human f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Human\"][\"recall\"][0] * df[df[\"label\"] == \"Human\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Human\"][\"precision\"][0]) + df[df[\"label\"] == \"Human\"][\"recall\"][0]), 2))\n",
    "try:\n",
    "    print(\"Elephant f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Elephant_African\"][\"recall\"][0] * df[df[\"label\"] == \"Elephant_African\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Elephant_African\"][\"precision\"][0]) + df[df[\"label\"] == \"Elephant_African\"][\"recall\"][0]), 2))\n",
    "except:\n",
    "    print(\"Elephant f0.5 score: \", 0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ce2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aggregated_cross_entropy_loss = {}\n",
    "\n",
    "for idx, pred in enumerate(y_pred):\n",
    "    loss = -math.log(pred[true_categories[idx]])\n",
    "    if CLASS_NAMES[true_categories[idx]] in mean_aggregated_cross_entropy_loss:\n",
    "        mean_aggregated_cross_entropy_loss[CLASS_NAMES[true_categories[idx]]].append(loss)\n",
    "    else:\n",
    "        mean_aggregated_cross_entropy_loss[CLASS_NAMES[true_categories[idx]]] = [loss]\n",
    "\n",
    "for keys, values in mean_aggregated_cross_entropy_loss.items():\n",
    "    mean = sum(values)/ len(values)\n",
    "    mean_aggregated_cross_entropy_loss[keys] = round(mean, 2)\n",
    "    \n",
    "# mean_aggregated_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae162d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean aggregated cross entropy loss:  0.65\n",
      "coss entropy loss Human:  0.86\n",
      "coss entropy loss Elephant:  0.67\n"
     ]
    }
   ],
   "source": [
    "mean_aggregated_cross_entropy_loss_final = []\n",
    "for key, value in mean_aggregated_cross_entropy_loss.items():\n",
    "    mean_aggregated_cross_entropy_loss_final.append(value)\n",
    "\n",
    "print(\"mean aggregated cross entropy loss: \", round(sum(mean_aggregated_cross_entropy_loss_final)/ len(mean_aggregated_cross_entropy_loss_final), 2))\n",
    "print(\"coss entropy loss Human: \", mean_aggregated_cross_entropy_loss[\"Human\"])\n",
    "print(\"coss entropy loss Elephant: \", mean_aggregated_cross_entropy_loss[\"Elephant_African\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197df4c",
   "metadata": {},
   "source": [
    "# SERENGETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "535923c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = 4\n",
    "elephant = 9\n",
    "blank = 12\n",
    "grouped = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fce3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_serengeti = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/serengeti_siebren.csv\", header=None)\n",
    "test_path_serengeti = \"gs://dataset-gabon/train_val_test_csv_Siebren/serengeti_siebren.csv\"\n",
    "test_ds_serengeti = load_dataset(test_path_serengeti, BATCH_SIZE, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29753a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(test_ds_serengeti, verbose=1)\n",
    "# print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96e0d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [06:53,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PREDICTIONS2 = len(test_data_serengeti)//BATCH_SIZE\n",
    "y_test2 = []\n",
    "counter2 = 0\n",
    "\n",
    "for i in tqdm(test_ds_serengeti):\n",
    "    if counter2 < PREDICTIONS2:\n",
    "        counter2 += 1\n",
    "        for j in i[1]:\n",
    "            if True in j:\n",
    "                y_test2.append(np.where(j == True)[0][0])\n",
    "            else:\n",
    "                y_test2.append(grouped)\n",
    "#                 y_test.append(10) # <- grouped\n",
    "    else:\n",
    "        break\n",
    "print(len(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34645d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds_serengeti, steps=PREDICTIONS2)\n",
    "predicted_categories2 = tf.argmax(y_pred, axis=1)\n",
    "true_categories = y_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6887e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_categories = []\n",
    "for i in predicted_categories2:\n",
    "#     if i.numpy() != 4 and i.numpy() != 9 and i.numpy() != 12:\n",
    "#         predicted_categories.append(28)\n",
    "#     if i.numpy() != 3 and i.numpy() != 4 and i.numpy() != 9: # <-- augmented\n",
    "#         predicted_categories.append(28)\n",
    "#     if i.numpy() != 2 and i.numpy() != 5 and i.numpy() != 6: # <-- grouped  \n",
    "#         predicted_categories.append(10)\n",
    "#     if i.numpy() != 13 and i.numpy() != 24 and i.numpy() != 25: # <-- augmented - balanced \n",
    "#         predicted_categories.append(28)\n",
    "    if i.numpy() != human and i.numpy() != elephant and i.numpy() != blank: # <-- no series\n",
    "        predicted_categories.append(grouped)\n",
    "    else:\n",
    "        predicted_categories.append(i.numpy())\n",
    "# predicted_categories = predicted_categories2 # <- 4classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd0111ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7235137195121951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>Elephant_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2343.0</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2772.0</td>\n",
       "      <td>Other_animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10496.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10496.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>10496.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall  f1-score  support             label\n",
       "4                 0.76   0.82      0.79   2680.0             Human\n",
       "9                 0.74   0.83      0.78   2701.0  Elephant_African\n",
       "12                0.67   0.71      0.69   2343.0             Blank\n",
       "28                 0.7   0.54      0.61   2772.0      Other_animal\n",
       "accuracy             -      -      0.72  10496.0                 -\n",
       "macro avg         0.72   0.72      0.72  10496.0                 -\n",
       "weighted avg      0.72   0.72      0.72  10496.0                 -"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = CLASS_NAMES.copy()\n",
    "new_labels = np.append(new_labels, \"Other_animal\")\n",
    "report = classification_report(true_categories, predicted_categories, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "print(df[\"precision\"][\"accuracy\"])\n",
    "a = pd.Series(list(new_labels))\n",
    "b = list(df.index[:-3])\n",
    "b = list(map(int, b))\n",
    "new_labels = list(a[b])\n",
    "if new_labels[len(new_labels) -1] != \"-\":\n",
    "    new_labels = np.append(new_labels, [\"-\", \"-\", \"-\"])\n",
    "df = df.round(decimals=2)\n",
    "df['label'] = new_labels\n",
    "df[\"precision\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"recall\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"support\"].iloc[len(new_labels) -3] = df[\"support\"].iloc[len(new_labels) -2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00f13df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f0.5 score:  0.35\n",
      "Human f0.5 score:  0.62\n",
      "Elephant f0.5 score:  0.0\n"
     ]
    }
   ],
   "source": [
    "macro_f1_score = []\n",
    "sum_list_recall = []\n",
    "sum_list_precision = []\n",
    "for idx, item in df.iterrows():\n",
    "    if idx != \"accuracy\" and idx != \"macro avg\" and idx != \"weighted avg\":\n",
    "        if item[\"label\"] == \"Human\" or item[\"label\"] == \"Elephant_African\" or item[\"label\"] == \"Blank\":\n",
    "            if item[\"precision\"] != 0 and item[\"recall\"] != 0:\n",
    "                macro_f1_score.append(1.5 * (item[\"precision\"] * item[\"recall\"]) / ((0.5*item[\"precision\"]) + item[\"recall\"]))\n",
    "            else:\n",
    "                macro_f1_score.append(0)\n",
    "        else:\n",
    "            sum_list_recall.append(item[\"recall\"])\n",
    "            sum_list_precision.append(item[\"precision\"])\n",
    "\n",
    "recall = sum(sum_list_recall) / len(sum_list_recall)\n",
    "precision = sum(sum_list_precision) / len(sum_list_precision)\n",
    "            \n",
    "macro_f1_score.append(1.5 * (precision * recall) / ((0.5*precision) + recall))\n",
    "\n",
    "print(\"Macro f0.5 score: \", round(sum(macro_f1_score) / len(macro_f1_score), 2))\n",
    "print(\"Human f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Human\"][\"recall\"][0] * df[df[\"label\"] == \"Human\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Human\"][\"precision\"][0]) + df[df[\"label\"] == \"Human\"][\"recall\"][0]), 2))\n",
    "try:\n",
    "    print(\"Elephant f0.5 score: \", round(1.5 * (df[df[\"label\"] == \"Elephant_African\"][\"recall\"][0] * df[df[\"label\"] == \"Elephant_African\"][\"precision\"][0]) / ((0.5*df[df[\"label\"] == \"Elephant_African\"][\"precision\"][0]) + df[df[\"label\"] == \"Elephant_African\"][\"recall\"][0]), 2))\n",
    "except:\n",
    "    print(\"Elephant f0.5 score: \", 0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5b16bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CLASS_NAMES = np.append(CLASS_NAMES, \"Other_animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70b7ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_aggregated_cross_entropy_loss = {}\n",
    "\n",
    "for idx, pred in enumerate(y_pred):\n",
    "#     if true_categories[idx] == 28:\n",
    "#         arr = np.delete(pred, [4,9,12])\n",
    "#         loss = -math.log(arr[tf.argmax(arr).numpy()])\n",
    "#     if true_categories[idx] == 10: # <-- grouped\n",
    "#         arr = np.delete(pred, [2,5,6])\n",
    "#         loss = -math.log(arr[tf.argmax(arr).numpy()])\n",
    "    if true_categories[idx] == grouped: # <-- no series\n",
    "        arr = np.delete(pred, [human,elephant,blank])\n",
    "        loss = -math.log(arr[tf.argmax(arr).numpy()])\n",
    "    else:    \n",
    "        loss = -math.log(pred[true_categories[idx]])\n",
    "    if NEW_CLASS_NAMES[true_categories[idx]] in mean_aggregated_cross_entropy_loss:\n",
    "        mean_aggregated_cross_entropy_loss[NEW_CLASS_NAMES[true_categories[idx]]].append(loss)\n",
    "    else:\n",
    "        mean_aggregated_cross_entropy_loss[NEW_CLASS_NAMES[true_categories[idx]]] = [loss]\n",
    "\n",
    "for keys, values in mean_aggregated_cross_entropy_loss.items():\n",
    "    mean = sum(values)/ len(values)\n",
    "    mean_aggregated_cross_entropy_loss[keys] = round(mean, 2)\n",
    "    \n",
    "# mean_aggregated_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36068507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean aggregated cross entropy loss:  1.03\n",
      "coss entropy loss Human:  0.62\n",
      "coss entropy loss Elephant:  0.87\n"
     ]
    }
   ],
   "source": [
    "mean_aggregated_cross_entropy_loss_final = []\n",
    "for key, value in mean_aggregated_cross_entropy_loss.items():\n",
    "    mean_aggregated_cross_entropy_loss_final.append(value)\n",
    "\n",
    "print(\"mean aggregated cross entropy loss: \", round(sum(mean_aggregated_cross_entropy_loss_final)/ len(mean_aggregated_cross_entropy_loss_final), 2))\n",
    "print(\"coss entropy loss Human: \", mean_aggregated_cross_entropy_loss[\"Human\"])\n",
    "print(\"coss entropy loss Elephant: \", mean_aggregated_cross_entropy_loss[\"Elephant_African\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa55ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff617fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad9cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f3778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377b4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1120eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(filename):\n",
    "    img = tf.io.read_file(filename=filename)\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    plt.figure(figsize = (16,16))\n",
    "    plt.imshow(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3cecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7631c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "# for idx, i in enumerate(true_categories):\n",
    "#     if i == 0:\n",
    "#         if i == predicted_categories[idx]:\n",
    "#             with warnings.catch_warnings():\n",
    "#                 # this will suppress all warnings in this block\n",
    "#                 warnings.simplefilter(\"ignore\")\n",
    "#                 show_img(test_data_myan[1][idx])\n",
    "#     #         print(\"True \", CLASS_NAMES[i])\n",
    "# #             print(\"Pred \", CLASS_NAMES[predicted_categories[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a1f91d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-421157ec4fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list= []\n",
    "for idx, i in enumerate(predicted_categories):\n",
    "    if i == 3:\n",
    "        if i == true_categories[idx]:\n",
    "            predict_list.append(y_pred[idx])\n",
    "\n",
    "elephant_c = []\n",
    "other_c = []\n",
    "blank_c= []\n",
    "human_c = []\n",
    "for i in predict_list:\n",
    "    elephant_c.append(i[0])\n",
    "    other_c.append(i[1])\n",
    "    blank_c.append(i[2])\n",
    "    human_c.append(i[3])\n",
    "    \n",
    "predict_list= []\n",
    "for idx, i in enumerate(predicted_categories):\n",
    "    if i == 3:\n",
    "        if i != true_categories[idx]:\n",
    "            predict_list.append(y_pred[idx])\n",
    "\n",
    "elephant_i = []\n",
    "other_i = []\n",
    "blank_i= []\n",
    "human_i = []\n",
    "for i in predict_list:\n",
    "    elephant_i.append(i[0])\n",
    "    other_i.append(i[1])\n",
    "    blank_i.append(i[2])\n",
    "    human_i.append(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects = ('Elephant_African', 'Other_animal', 'Blank', 'Human')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance_c = [sum(elephant_c) / len(elephant_c),sum(other_c) / len(other_c),sum(blank_c) / len(blank_c),sum(human_c) / len(human_c)]\n",
    "performance_i = [sum(elephant_i) / len(elephant_i),sum(other_i) / len(other_i),sum(blank_i) / len(blank_i),sum(human_i) / len(human_i)]\n",
    "\n",
    "# # plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "# plt.xticks(y_pos, objects)\n",
    "# plt.ylabel('Probability')\n",
    "# # plt.title('Incorrect predictions elephant')\n",
    "# plt.ylim([0, 1])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax.set_title('Full view')\n",
    "ax.bar(y_pos, performance_c, align='center', alpha=0.5)\n",
    "\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "ax2.set_title('Truncated view')\n",
    "ax2.bar(y_pos, performance_i, align='center', alpha=0.5)\n",
    "\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041657d",
   "metadata": {},
   "source": [
    "# todo CHECK WITH LESS HUMANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d93fba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_siebren_4classes.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e917ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = test_data[test_data[0] == \"Other_animal\"].sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e98595fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = test_data[test_data[0] != \"Other_animal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb647eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = rest.append(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6233e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = new_test.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d814d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blank</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elephant_African</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other_animal</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1\n",
       "0                     \n",
       "Blank             5000\n",
       "Elephant_African  5000\n",
       "Human             5000\n",
       "Other_animal      5000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.groupby(0).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78d968e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test.to_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_human.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a28064a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_myan = \"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_human.csv\"\n",
    "test_ds_myan = load_dataset(test_path_myan, BATCH_SIZE, training=False)\n",
    "# test_loss, test_acc = model.evaluate(test_ds_myan, verbose=1)\n",
    "# print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b60bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_myan = pd.read_csv(\"gs://dataset-gabon/train_val_test_csv_Siebren/test_data_human.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b777485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [02:35,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PREDICTIONS = len(test_data_myan)//BATCH_SIZE\n",
    "y_test = []\n",
    "counter = 0\n",
    "for i in tqdm(test_ds_myan):\n",
    "    counter += 1\n",
    "    for j in i[1]:\n",
    "        y_test.append(np.where(j == True)[0][0])\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "279cad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(test_ds_myan)\n",
    "# predicted_categories = []\n",
    "# true_categories = []\n",
    "# for idx, i in enumerate(y_pred):\n",
    "#     if np.amax(i) > 0.9:\n",
    "#         predicted_categories.append(np.argmax(i))\n",
    "#         true_categories.append(y_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99912cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_labels = CLASS_NAMES.copy()\n",
    "# report = classification_report(true_categories, predicted_categories, output_dict=True)\n",
    "# df = pd.DataFrame(report).transpose()\n",
    "# a = pd.Series(list(new_labels))\n",
    "# b = list(df.index[:-3])\n",
    "# b = list(map(int, b))\n",
    "# new_labels = list(a[b])\n",
    "# if new_labels[len(new_labels) -1] != \"-\":\n",
    "#     new_labels = np.append(new_labels, [\"-\", \"-\", \"-\"])\n",
    "# df = df.round(decimals=2)\n",
    "# df['label'] = new_labels\n",
    "# df[\"precision\"].iloc[len(new_labels) -3] = \"-\"\n",
    "# df[\"recall\"].iloc[len(new_labels) -3] = \"-\"\n",
    "# df[\"support\"].iloc[len(new_labels) -3] = df[\"support\"].iloc[len(new_labels) -2]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2401b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ds_myan)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "true_categories = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52abf69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Other_animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Elephant_African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>Blank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.82</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall  f1-score  support             label\n",
       "0                 0.66   0.94      0.77   5000.0      Other_animal\n",
       "1                 0.93   0.84      0.88   5000.0             Human\n",
       "2                 0.88   0.76      0.81   5000.0  Elephant_African\n",
       "3                 0.91   0.73      0.81   5000.0             Blank\n",
       "accuracy             -      -      0.82  20000.0                 -\n",
       "macro avg         0.84   0.82      0.82  20000.0                 -\n",
       "weighted avg      0.84   0.82      0.82  20000.0                 -"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels = CLASS_NAMES.copy()\n",
    "report = classification_report(true_categories, predicted_categories, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "a = pd.Series(list(new_labels))\n",
    "b = list(df.index[:-3])\n",
    "b = list(map(int, b))\n",
    "new_labels = list(a[b])\n",
    "if new_labels[len(new_labels) -1] != \"-\":\n",
    "    new_labels = np.append(new_labels, [\"-\", \"-\", \"-\"])\n",
    "df = df.round(decimals=2)\n",
    "df['label'] = new_labels\n",
    "df[\"precision\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"recall\"].iloc[len(new_labels) -3] = \"-\"\n",
    "df[\"support\"].iloc[len(new_labels) -3] = df[\"support\"].iloc[len(new_labels) -2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "91b15cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_list= []\n",
    "# for idx, i in enumerate(predicted_categories):\n",
    "#     if i == 1:\n",
    "#         if i == true_categories[idx]:\n",
    "#             predict_list.append(y_pred[idx])\n",
    "\n",
    "# elephant_c = []\n",
    "# other_c = []\n",
    "# blank_c= []\n",
    "# human_c = []\n",
    "# for i in predict_list:\n",
    "#     elephant_c.append(i[0])\n",
    "#     other_c.append(i[1])\n",
    "#     blank_c.append(i[2])\n",
    "#     human_c.append(i[3])\n",
    "    \n",
    "# predict_list= []\n",
    "# for idx, i in enumerate(predicted_categories):\n",
    "#     if i == 1:\n",
    "#         if i != true_categories[idx]:\n",
    "#             predict_list.append(y_pred[idx])\n",
    "\n",
    "# elephant_i = []\n",
    "# other_i = []\n",
    "# blank_i= []\n",
    "# human_i = []\n",
    "# for i in predict_list:\n",
    "#     elephant_i.append(i[0])\n",
    "#     other_i.append(i[1])\n",
    "#     blank_i.append(i[2])\n",
    "#     human_i.append(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f10c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# objects = ('Elephant_African', 'Other_animal', 'Blank', 'Human')\n",
    "# y_pos = np.arange(len(objects))\n",
    "# performance_c = [sum(elephant_c) / len(elephant_c),sum(other_c) / len(other_c),sum(blank_c) / len(blank_c),sum(human_c) / len(human_c)]\n",
    "# performance_i = [sum(elephant_i) / len(elephant_i),sum(other_i) / len(other_i),sum(blank_i) / len(blank_i),sum(human_i) / len(human_i)]\n",
    "\n",
    "# # # plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "# # plt.xticks(y_pos, objects)\n",
    "# # plt.ylabel('Probability')\n",
    "# # # plt.title('Incorrect predictions elephant')\n",
    "# # plt.ylim([0, 1])\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ax = fig.add_subplot(121)\n",
    "# ax2 = fig.add_subplot(122)\n",
    "\n",
    "# ax.set_title('Correct predictions human')\n",
    "# ax.bar(y_pos, performance_c, align='center', alpha=0.5)\n",
    "# ax.set_xticks([0,1,2,3]) \n",
    "# ax.set_xticklabels(['Other_animal','Human','Elephant_African','Blank'])\n",
    "\n",
    "# ax.set_ylim([0, 1])\n",
    "\n",
    "# ax2.set_title('Incorrect predictions human')\n",
    "# ax2.bar(y_pos, performance_i, align='center', alpha=0.5)\n",
    "# ax2.set_xticks([0,1,2,3]) \n",
    "# ax2.set_xticklabels(['Other_animal','Human','Elephant_African','Blank'])\n",
    "\n",
    "# ax2.set_ylim([0, 1])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "952c0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elephant = []\n",
    "# other = []\n",
    "# blank= []\n",
    "# human = []\n",
    "# for i in predicted_categories:\n",
    "#     if i == 0:\n",
    "#         other.append(i)\n",
    "#     if i == 1:\n",
    "#         human.append(i)\n",
    "#     if i == 2:\n",
    "#         elephant.append(i)\n",
    "#     if i == 3:\n",
    "#         blank.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d01760b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "other = 0\n",
    "human = 0\n",
    "elephant = 0 \n",
    "blank = 0\n",
    "for idx, i in enumerate(predicted_categories):\n",
    "    if i == 0:\n",
    "        other += 1\n",
    "    if i == 1:\n",
    "        human += 1\n",
    "    if i == 2:\n",
    "        elephant += 1\n",
    "    if i == 3:\n",
    "        blank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec5b16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other: 7140, human: 4507, elephant: 4332, blank: 4021\n"
     ]
    }
   ],
   "source": [
    "print(f\"other: {other}, human: {human}, elephant: {elephant}, blank: {blank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1789d315",
   "metadata": {},
   "source": [
    "true_human: 100, pred_human: 1589, tp_human: 84, fp_human: 1505, fn_human: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2fc3d3",
   "metadata": {},
   "source": [
    "true_human: 500, pred_human: 1929, tp_human: 424, fp_human: 1505, fn_human: 76"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f60e2",
   "metadata": {},
   "source": [
    "true_human: 1000, pred_human: 2362, tp_human: 857, fp_human: 1505, fn_human: 143"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b96d4",
   "metadata": {},
   "source": [
    "true_human: 2500, pred_human: 3625, tp_human: 2120, fp_human: 1505, fn_human: 380"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d6c1e",
   "metadata": {},
   "source": [
    "true_human: 5000, pred_human: 5761, tp_human: 4256, fp_human: 1505, fn_human: 744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6e38ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_list = {0:0, 1:0, 3:0}\n",
    "for idx, i in enumerate(predicted_categories):\n",
    "    if i == 2 and true_categories[idx] != 2:\n",
    "        fp_list[true_categories[idx]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "464713e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1197, 1: 191, 3: 117}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1592e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c399fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced\n",
    "Human &\t24104 & 5000 & 4835 \\\\\n",
    "Blank &\t23956 & 5000 & 5000 \\\\\n",
    "Elephant African & 24054 & 5000 & 5376 \\\\\n",
    "Other animal & 171514 & 5000 & 4835 \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Human &\t24104 & 5000 & 4507 \\\\\n",
    "Blank &\t23956 & 5000 & 4021 \\\\\n",
    "Elephant African & 24054 & 5000 & 4332 \\\\\n",
    "Other animal & 171514 & 5000 & 7140 \\\\"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
